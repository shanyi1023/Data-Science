{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Movie Ratings by Web Scraping (Beautiful Soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read my medium article about it [here](https://medium.com/@shanyitan/automated-web-scraping-using-beautifulsoup-for-dummies-free-python-code-41925125774e).\n",
    "\n",
    "Next, you can get the EDA of this dataset here (link to be updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Requests to download page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start scraping a web page, first we need to download the page using the Python ``requests library``. The requests library will make a ``GET`` request to a web server, which will download the HTML contents of a given web page for us. There are several different types of requests we can make using requests, of which GET is just one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install ``requests`` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to install it. Voila!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sytan\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "<!DOCTYPE html>\n",
      "<html\n",
      "    xmlns:og=\"http://ogp.me/ns#\"\n",
      "    xmlns:fb=\"http://www.facebook.com/2008/fbml\">\n",
      "    <head>\n",
      "         \n",
      "        <meta charset=\"utf-8\">\n",
      "        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n",
      "\n",
      "    <meta name=\"apple-itunes-app\" content=\"app-id=342792525, app-argument=imdb:///?src=mdot\">\n",
      "\n",
      "\n",
      "\n",
      "        <script type=\"text/javascript\">var IMDbTimer={starttime: new Date().getTime(),pt:'java'};</script>\n",
      "\n",
      "<script>\n",
      "    if (typeof uet == 'function') {\n",
      "      uet(\"bb\", \"LoadTitle\"\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "\n",
    "# request the server the content of the web page by using get()\n",
    "# store the server’s response in the variable response.\n",
    "response = get('http://www.imdb.com/search/title?release_date=2019&sort=num_votes,desc&page=1')\n",
    "\n",
    "# print a small part of response's content by accessing its .text attribute\n",
    "# (response is now a Response object).\n",
    "print(response.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the first line of ``response.text``, the server sent us an HTML document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BeautifulSoup to parse the HTML content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To parse our HTML document and extract the HTML, we’ll use a Python module called BeautifulSoup. In the following code cell we will:\n",
    "\n",
    "- Import the BeautifulSoup from the package bs4.\n",
    "- Parse ``response.text`` by creating a BeautifulSoup object, and assign this object to ``html_soup``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install ``BeautifulSoup`` library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code below to install it. Easy peasy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\sytan\\anaconda3\\lib\\site-packages (from BeautifulSoup4) (1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The 'html.parser' argument indicates that we want to do the\n",
    "# parsing using Python’s built-in HTML parser.\n",
    "html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "type(html_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the HTML structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you get all hyped up for web scraping, you need to understand the HTML of the website which you want to scrape from. Take note that every website has different structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Images/movie ratings 1.jpg\" width =\"500\" height=500 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Right click on the website\n",
    "2. Left click on ``Inspect``\n",
    "3. Turn on the hover cursor button on top left.\n",
    "\n",
    "Each movie is in a ``div`` tag with class ``lister-item-mode-advanced``. Let’s use the ``find_all()`` method to extract all the ``div containers`` that have a class attribute of ``lister-item mode-advanced``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bs4.element.ResultSet'>\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "movie_containers = html_soup.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "print(type(movie_containers))\n",
    "print(len(movie_containers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown, there are 50 containers, meaning to say 50 movies listed on each page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Images/movie ratings 2.jpg\" width =\"500\" height=500 >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we’ll select only the first container, and extract, by turn, each item of interest:\n",
    "\n",
    "    - The name of the movie.\n",
    "    - The year of release.\n",
    "    - The IMDB rating.\n",
    "    - The Metascore.\n",
    "    - Directors\n",
    "    - The number of votes.\n",
    "    - Gross\n",
    "    \n",
    "Let's get started with the ``first_movie``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stored the content of this container in the first_movie variable\n",
    "first_movie = movie_containers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"lister-item mode-advanced\">\n",
       "<div class=\"lister-top-right\">\n",
       "<div class=\"ribbonize\" data-caller=\"filmosearch\" data-tconst=\"tt4154796\"></div>\n",
       "</div>\n",
       "<div class=\"lister-item-image float-left\">\n",
       "<a href=\"/title/tt4154796/\"> <img alt=\"Avengers: Endgame\" class=\"loadlate\" data-tconst=\"tt4154796\" height=\"98\" loadlate=\"https://m.media-amazon.com/images/M/MV5BMTc5MDE2ODcwNV5BMl5BanBnXkFtZTgwMzI2NzQ2NzM@._V1_UX67_CR0,0,67,98_AL_.jpg\" src=\"https://m.media-amazon.com/images/G/01/imdb/images/nopicture/large/film-184890147._CB470041630_.png\" width=\"67\"/>\n",
       "</a> </div>\n",
       "<div class=\"lister-item-content\">\n",
       "<h3 class=\"lister-item-header\">\n",
       "<span class=\"lister-item-index unbold text-primary\">1.</span>\n",
       "<a href=\"/title/tt4154796/\">Avengers: Endgame</a>\n",
       "<span class=\"lister-item-year text-muted unbold\">(2019)</span>\n",
       "</h3>\n",
       "<p class=\"text-muted\">\n",
       "<span class=\"certificate\">P13</span>\n",
       "<span class=\"ghost\">|</span>\n",
       "<span class=\"runtime\">181 min</span>\n",
       "<span class=\"ghost\">|</span>\n",
       "<span class=\"genre\">\n",
       "Action, Adventure, Drama            </span>\n",
       "</p>\n",
       "<div class=\"ratings-bar\">\n",
       "<div class=\"inline-block ratings-imdb-rating\" data-value=\"8.5\" name=\"ir\">\n",
       "<span class=\"global-sprite rating-star imdb-rating\"></span>\n",
       "<strong>8.5</strong>\n",
       "</div>\n",
       "<div class=\"inline-block ratings-user-rating\">\n",
       "<span class=\"userRatingValue\" data-tconst=\"tt4154796\" id=\"urv_tt4154796\">\n",
       "<span class=\"global-sprite rating-star no-rating\"></span>\n",
       "<span class=\"rate\" data-no-rating=\"Rate this\" data-value=\"0\" name=\"ur\">Rate this</span>\n",
       "</span>\n",
       "<div class=\"starBarWidget\" id=\"sb_tt4154796\">\n",
       "<div class=\"rating rating-list\" data-auth=\"\" data-ga-identifier=\"\" data-starbar-class=\"rating-list\" data-user=\"\" id=\"tt4154796|imdb|8.5|8.5|||advsearch|title\" itemprop=\"aggregateRating\" itemscope=\"\" itemtype=\"http://schema.org/AggregateRating\" title=\"Users rated this 8.5/10 (636,582 votes) - click stars to rate\">\n",
       "<meta content=\"8.5\" itemprop=\"ratingValue\"/>\n",
       "<meta content=\"10\" itemprop=\"bestRating\"/>\n",
       "<meta content=\"636582\" itemprop=\"ratingCount\"/>\n",
       "<span class=\"rating-bg\"> </span>\n",
       "<span class=\"rating-imdb\" style=\"width: 119px\"> </span>\n",
       "<span class=\"rating-stars\">\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>1</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>2</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>3</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>4</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>5</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>6</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>7</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>8</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>9</span></a>\n",
       "<a href=\"/register/login?why=vote\" rel=\"nofollow\" title=\"Register or login to rate this title\"><span>10</span></a>\n",
       "</span>\n",
       "<span class=\"rating-rating\"><span class=\"value\">8.5</span><span class=\"grey\">/</span><span class=\"grey\">10</span></span>\n",
       "<span class=\"rating-cancel\"><a href=\"/title/tt4154796/vote?v=X;k=\" rel=\"nofollow\" title=\"Delete\"><span>X</span></a></span>\n",
       " </div>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"inline-block ratings-metascore\">\n",
       "<span class=\"metascore favorable\">78        </span>\n",
       "        Metascore\n",
       "            </div>\n",
       "</div>\n",
       "<p class=\"text-muted\">\n",
       "    After the devastating events of <a href=\"/title/tt4154756\">Avengers: Infinity War</a> (2018), the universe is in ruins. With the help of remaining allies, the Avengers assemble once more in order to reverse Thanos' actions and restore balance to the universe.</p>\n",
       "<p class=\"\">\n",
       "    Directors:\n",
       "<a href=\"/name/nm0751577/\">Anthony Russo</a>, \n",
       "<a href=\"/name/nm0751648/\">Joe Russo</a>\n",
       "<span class=\"ghost\">|</span> \n",
       "    Stars:\n",
       "<a href=\"/name/nm0000375/\">Robert Downey Jr.</a>, \n",
       "<a href=\"/name/nm0262635/\">Chris Evans</a>, \n",
       "<a href=\"/name/nm0749263/\">Mark Ruffalo</a>, \n",
       "<a href=\"/name/nm1165110/\">Chris Hemsworth</a>\n",
       "</p>\n",
       "<p class=\"sort-num_votes-visible\">\n",
       "<span class=\"text-muted\">Votes:</span>\n",
       "<span data-value=\"636582\" name=\"nv\">636,582</span>\n",
       "<span class=\"ghost\">|</span> <span class=\"text-muted\">Gross:</span>\n",
       "<span data-value=\"858,373,000\" name=\"nv\">$858.37M</span>\n",
       "</p>\n",
       "</div>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the ``first_movie`` html which we had stored, we are going to use ``find`` and ``find_all`` with ``str slicing`` to work out the magic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The name of the movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Avengers: Endgame'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.h3.a.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The year of release."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(2019)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.h3.find('span', class_ = 'lister-item-year text-muted unbold').text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The IMDB rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'8.5'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.strong.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Metascore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(first_movie.find('span', class_ = 'metascore favorable').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is more complicated as this class contains **Directors** and **Stars**. So I used slicing and splitting to extract only the directors. You may use the same logic to extract Stars as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p class=\"\">\n",
       "    Directors:\n",
       "<a href=\"/name/nm0751577/\">Anthony Russo</a>, \n",
       "<a href=\"/name/nm0751648/\">Joe Russo</a>\n",
       "<span class=\"ghost\">|</span> \n",
       "    Stars:\n",
       "<a href=\"/name/nm0000375/\">Robert Downey Jr.</a>, \n",
       "<a href=\"/name/nm0262635/\">Chris Evans</a>, \n",
       "<a href=\"/name/nm0749263/\">Mark Ruffalo</a>, \n",
       "<a href=\"/name/nm1165110/\">Chris Hemsworth</a>\n",
       "</p>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.find('p', class_ = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Anthony Russo, Joe Russo'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use slicer [2:-2] to select only directors' names\n",
    "a = first_movie.find('p', class_ = '').text.split('Stars')[0].split('\\n')[2:-2]\n",
    "\n",
    "# join the string together\n",
    "a = ''.join(a)\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The number of votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'636582'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.find_all('span', attrs = {'name':'nv'})[0]['data-value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'858,373,000'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_movie.find_all('span', attrs = {'name':'nv'})[1]['data-value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensure you get the right data in English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a side note, if you run the code from a country where English is not the main language, it’s very likely that you’ll get some of the movie names translated into the main language of that country.\n",
    "\n",
    "Most likely, this happens because the server infers your location from your IP address. Even if you are located in a country where English is the main language, you may still get translated content. This may happen if you’re using a VPN while you’re making the GET requests.\n",
    "\n",
    "If you run into this issue, pass the following values to the headers parameter of the get() function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will communicate the server something like “I want the linguistic content in American English (en-US). If en-US is not available, then other types of English (en) would be fine too (but not as much as en-US).”. The q parameter indicates the degree to which we prefer a certain language. If not specified, then the values is set to 1 by default, like in the case of en-US. You can read more about this here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing the URL’s parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The URLs follow a certain logic as the web pages change. As we are making the requests, we’ll only have to vary the values of only two parameters of the URL:\n",
    "- ``release_date`` : Create a list called **years_url** and populate it with the strings corresponding to the years 2000-2017.\n",
    "- ``page`` : Create a list called **pages**, and populate it with the strings corresponding to the first 4 pages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = [str(i) for i in range(1,5)]\n",
    "years_url = [str(i) for i in range(2000,2018)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling the crawl-rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do so?\n",
    "- Less likely to get our IP address banned by avoid hammering the server with tens of requests per second\n",
    "- Avoid disrupting and overloading the server so that it can respond to other users’ requests.\n",
    "\n",
    "We need 2 functions:\n",
    "1. ``sleep()``: Control the loop’s rate. It will pause the execution of the loop for a specified amount of seconds.\n",
    "2. ``randint()``: To mimic human behavior, we’ll vary the amount of waiting time between requests. It  randomly generates integers within a specified interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monitoring the loop as it’s still going"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitoting is very helpful in the testing and debugging process, especially if you are going to scrape hundreds or thousands of web pages in a single code run. Here are the following parameters that we are gonna monitor:\n",
    "\n",
    "1. The **frequency (speed) of requests**: make sure our program is not overloading the server.\n",
    "\n",
    "    ``Frequency value = the number of requests / the time elapsed since the first request.``\n",
    "\n",
    "2. The **number of requests**: can halt the loop in case the number of expected requests is exceeded.\n",
    "3. The **status code of our requests**: make sure the server is sending back the proper responses.\n",
    "\n",
    "Let’s experiment with this monitoring technique at a small scale first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 1; Frequency: 0.9985465701078157 requests/s\n",
      "Request: 2; Frequency: 0.4996984632467085 requests/s\n",
      "Request: 3; Frequency: 0.4282898904634903 requests/s\n",
      "Request: 4; Frequency: 0.39972687310084826 requests/s\n",
      "Request: 5; Frequency: 0.454000337412322 requests/s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "# Set a starting time using the time() function from the time module, and assign the value to start_time.\n",
    "start_time = time()\n",
    "\n",
    "# Assign 0 to the variable requests which we’ll use to count the number of requests.\n",
    "request = 0\n",
    "\n",
    "#Start a loop, and then with each iteration:\n",
    "    #- Simulate a request.\n",
    "    #- Increment the number of requests by 1.\n",
    "    #- Pause the loop for a time interval between 8 and 15 seconds.\n",
    "    #- Calculate the elapsed time since the first request, and assign the value to elapsed_time.\n",
    "    #- Print the number of requests and the frequency.\n",
    "    \n",
    "for _ in range(5):\n",
    "    request += 1\n",
    "    sleep(randint(1,3))\n",
    "    elapsed_time = time() - start_time\n",
    "    print('Request: {}; Frequency: {} requests/s'.format(request, request/elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we’re going to more than 5 requests, our work will look a bit untidy as the output accumulates. To avoid that, we’ll clear the output after each iteration, and replace it with information about the most recent request.\n",
    "\n",
    "How:\n",
    "1. Use the ``clear_output()`` function from the ``IPython’s core.display module``.\n",
    "2. Set the ``wait parameter`` of clear_output() to ``True`` to wait with replacing the current output until some new output appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request: 5; Frequency: 0.5537280012707625 requests/s\n"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import clear_output\n",
    "\n",
    "start_time = time()\n",
    "request = 0\n",
    "\n",
    "for _ in range(5):\n",
    "    request += 1\n",
    "    sleep(randint(1,3))\n",
    "    current_time = time()\n",
    "    elapsed_time = current_time - start_time\n",
    "    print('Request: {}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "    clear_output(wait = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To monitor the status code we’ll set the program to warn us if there’s something off. A successful request is indicated by a status code of 200. We’ll use the ``warn()`` function from the warnings module to throw a warning if the status code is not 200.\n",
    "\n",
    "We chose a warning over breaking the loop because there’s a good possibility we’ll scrape enough data, even if some of the requests fail. We will only break the loop if the number of requests is greater than expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SYTan\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Warning Simulation\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "from warnings import warn\n",
    "warn(\"Warning Simulation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Piece everything together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Phew~ Tough work is done, now let’s piece together everything we’ve done so far.\n",
    "\n",
    "1. **Import** necessary libraries\n",
    "2. **Re-declare the lists variables** so they become empty again.\n",
    "3. Prepare the loop.\n",
    "4. **Loop through the years_url list** in the interval 2010-2019 and **loop through the pages list** in the interval 1-4.\n",
    "5. Make the **GET requests** within the pages loop\n",
    "6. Give the **headers** parameter the right value to make sure we get only English content.\n",
    "7. Pause the loop for a **time interval** between 8 and 15 seconds.\n",
    "9. Throw a **warning for non-200 status codes**.\n",
    "10. Break the loop if the **number of requests is greater than expected**.\n",
    "11. Convert the response‘s HTML content to a BeautifulSoup object.\n",
    "12. Extract all **movie containers** from this BeautifulSoup object.\n",
    "13. **Loop through** all these containers.\n",
    "14. Extract the data if a container has a **Metascore**.\n",
    "15. Extract the data if a container has a **Gross**, or else append(\"-\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request:40; Frequency: 0.054821971856423284 requests/s\n"
     ]
    }
   ],
   "source": [
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "from time import time, sleep\n",
    "from random import randint\n",
    "from IPython.core.display import clear_output\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "\n",
    "# Redeclare the lists to store data in\n",
    "names = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "metascores = []\n",
    "directors = []\n",
    "votes = []\n",
    "gross = []\n",
    "\n",
    "# Prepare the loop\n",
    "start_time = time()\n",
    "request = 0\n",
    "\n",
    "pages = [str(i) for i in range(1,5)]\n",
    "years_url = [str(i) for i in range(2010,2020)]\n",
    "\n",
    "# For every year in the interval 2010-2019\n",
    "for year_url in years_url:\n",
    "\n",
    "    # For every page in the interval 1-4\n",
    "    for page in pages:\n",
    "\n",
    "        # Make a get request\n",
    "        # Exp: https://www.imdb.com/search/title/?release_date=2019&sort=num_votes,desc&page=1\n",
    "        response = get('http://www.imdb.com/search/title?release_date='+year_url+'&sort=num_votes,desc&page='+page, headers = headers)\n",
    "\n",
    "        # Pause the loop\n",
    "        sleep(randint(8,15))\n",
    "\n",
    "        # Monitor the requests\n",
    "        request += 1\n",
    "        elapsed_time = time() - start_time\n",
    "        print('Request:{}; Frequency: {} requests/s'.format(request, request/elapsed_time))\n",
    "        clear_output(wait = True)\n",
    "\n",
    "        # Throw a warning for non-200 status codes\n",
    "        if response.status_code != 200:\n",
    "            warn('Request: {}; Status code: {}'.format(request, response.status_code))\n",
    "\n",
    "        # Break the loop if the number of requests is greater than expected\n",
    "        # 4 pages * 10 years = 40 requests\n",
    "        if request > 40:\n",
    "            warn('Number of requests was greater than expected.')\n",
    "            break\n",
    "\n",
    "        # Parse the content of the request with BeautifulSoup\n",
    "        page_html = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Select all the 50 movie containers from a single page\n",
    "        mv_containers = page_html.find_all('div', class_ = 'lister-item mode-advanced')\n",
    "\n",
    "        # For every movie of these 50\n",
    "        for container in mv_containers:\n",
    "            # If the movie has a Metascore, then:\n",
    "            if container.find('div', class_ = 'ratings-metascore') is not None:\n",
    "\n",
    "                # Scrape the name\n",
    "                name = container.h3.a.text\n",
    "                names.append(name)\n",
    "\n",
    "                # Scrape the year\n",
    "                year = container.h3.find('span', class_ = 'lister-item-year').text\n",
    "                years.append(year)\n",
    "\n",
    "                # Scrape the IMDB rating\n",
    "                imdb = float(container.strong.text)\n",
    "                imdb_ratings.append(imdb)\n",
    "\n",
    "                # Scrape the Metascore\n",
    "                m_score = container.find('span', class_ = 'metascore').text\n",
    "                metascores.append(int(m_score))\n",
    "                \n",
    "                # Scrape the directors\n",
    "                director = ''.join(container.find('p', class_ = '').text.split('Stars')[0].split('\\n')[2:-2])\n",
    "                directors.append(director)\n",
    "\n",
    "                # Scrape the number of votes\n",
    "                vote = container.find_all('span', attrs = {'name':'nv'})[0]['data-value']\n",
    "                votes.append(int(vote))\n",
    "                \n",
    "                # If the movie has a Gross, then:\n",
    "                if len(container.find_all('span', attrs = {'name':'nv'})) >= 2:\n",
    "                    \n",
    "                    # Scrape the gross\n",
    "                    gross_value = container.find_all('span', attrs = {'name':'nv'})[1]['data-value']\n",
    "                    gross.append(gross_value)\n",
    "                    \n",
    "                else:\n",
    "                    gross.append(\"-\")        \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the scraped data into CSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code block we:\n",
    "- Merge the data into a pandas DataFrame.\n",
    "- Print some informations about the newly created DataFrame.\n",
    "- Show the last 10 entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1788 entries, 0 to 1787\n",
      "Data columns (total 7 columns):\n",
      "movie        1788 non-null object\n",
      "year         1788 non-null object\n",
      "imdb         1788 non-null float64\n",
      "metascore    1788 non-null int64\n",
      "directors    1788 non-null object\n",
      "votes        1788 non-null int64\n",
      "gross($)     1788 non-null object\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 97.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>year</th>\n",
       "      <th>imdb</th>\n",
       "      <th>metascore</th>\n",
       "      <th>directors</th>\n",
       "      <th>votes</th>\n",
       "      <th>gross($)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>Rocketman</td>\n",
       "      <td>(I) (2019)</td>\n",
       "      <td>7.4</td>\n",
       "      <td>69</td>\n",
       "      <td>Dexter Fletcher</td>\n",
       "      <td>85926</td>\n",
       "      <td>96,368,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>How to Train Your Dragon: The Hidden World</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>7.5</td>\n",
       "      <td>71</td>\n",
       "      <td>Dean DeBlois</td>\n",
       "      <td>82861</td>\n",
       "      <td>160,799,505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>Men in Black: International</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>5.6</td>\n",
       "      <td>38</td>\n",
       "      <td>F. Gary Gray</td>\n",
       "      <td>80819</td>\n",
       "      <td>79,800,736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>Murder Mystery</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>6.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Kyle Newacheck</td>\n",
       "      <td>77429</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>Ford v Ferrari</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>8.3</td>\n",
       "      <td>81</td>\n",
       "      <td>James Mangold</td>\n",
       "      <td>75836</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>6 Underground</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>6.1</td>\n",
       "      <td>41</td>\n",
       "      <td>Michael Bay</td>\n",
       "      <td>74433</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1784</th>\n",
       "      <td>Yesterday</td>\n",
       "      <td>(III) (2019)</td>\n",
       "      <td>6.9</td>\n",
       "      <td>55</td>\n",
       "      <td>Danny Boyle</td>\n",
       "      <td>72179</td>\n",
       "      <td>73,286,650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>Pet Sematary</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>5.8</td>\n",
       "      <td>57</td>\n",
       "      <td>Kevin Kölsch, Dennis Widmyer</td>\n",
       "      <td>64555</td>\n",
       "      <td>54,724,696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>Escape Room</td>\n",
       "      <td>(I) (2019)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>48</td>\n",
       "      <td>Adam Robitel</td>\n",
       "      <td>64168</td>\n",
       "      <td>57,005,601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>Polar</td>\n",
       "      <td>(I) (2019)</td>\n",
       "      <td>6.3</td>\n",
       "      <td>19</td>\n",
       "      <td>Jonas Åkerlund</td>\n",
       "      <td>63653</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           movie          year  imdb  \\\n",
       "1778                                   Rocketman    (I) (2019)   7.4   \n",
       "1779  How to Train Your Dragon: The Hidden World        (2019)   7.5   \n",
       "1780                 Men in Black: International        (2019)   5.6   \n",
       "1781                              Murder Mystery        (2019)   6.0   \n",
       "1782                              Ford v Ferrari        (2019)   8.3   \n",
       "1783                               6 Underground        (2019)   6.1   \n",
       "1784                                   Yesterday  (III) (2019)   6.9   \n",
       "1785                                Pet Sematary        (2019)   5.8   \n",
       "1786                                 Escape Room    (I) (2019)   6.3   \n",
       "1787                                       Polar    (I) (2019)   6.3   \n",
       "\n",
       "      metascore                     directors  votes     gross($)  \n",
       "1778         69               Dexter Fletcher  85926   96,368,160  \n",
       "1779         71                  Dean DeBlois  82861  160,799,505  \n",
       "1780         38                  F. Gary Gray  80819   79,800,736  \n",
       "1781         38                Kyle Newacheck  77429            -  \n",
       "1782         81                 James Mangold  75836            -  \n",
       "1783         41                   Michael Bay  74433            -  \n",
       "1784         55                   Danny Boyle  72179   73,286,650  \n",
       "1785         57  Kevin Kölsch, Dennis Widmyer  64555   54,724,696  \n",
       "1786         48                  Adam Robitel  64168   57,005,601  \n",
       "1787         19                Jonas Åkerlund  63653            -  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "movie_ratings = pd.DataFrame({'movie': names,\n",
    "'year': years,\n",
    "'imdb': imdb_ratings,\n",
    "'metascore': metascores,\n",
    "'directors': directors,\n",
    "'votes': votes,\n",
    "'gross($)': gross,\n",
    "})\n",
    "print(movie_ratings.info())\n",
    "movie_ratings.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ratings.to_csv('movie_ratings_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
